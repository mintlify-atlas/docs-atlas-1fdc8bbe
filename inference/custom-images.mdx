---
title: Predicting custom images
description: Use your trained neural network to classify custom 28×28 PNG images of handwritten digits
---

After training your neural network, you can make predictions on custom images. This is useful for testing your own handwritten digits or evaluating the model on new data.

## Quick start

Predict a digit from a 28×28 PNG image:

```bash
go run cmd/main.go -file path/to/image.png
```

The command will display the image in your terminal (if supported) and output the predicted digit.

## Image requirements

<Warning>
  Your image must meet specific requirements for accurate predictions. Incorrect formatting will lead to poor results.
</Warning>

### Format specifications

- **Dimensions**: Exactly 28×28 pixels
- **Format**: PNG
- **Color mode**: Grayscale (or will be converted to grayscale)
- **Digit color**: White digit on black background (inverted from normal)
- **Content**: Single centered digit

<Note>
  The MNIST dataset uses inverted colors (white on black), so your custom images must follow the same format. A black digit on white background will not work correctly.
</Note>

## Preparing your image

<Steps>
  <Step title="Create or obtain a 28×28 image">
    Use an image editor to create a 28×28 pixel PNG file. Most image editors allow you to set exact dimensions:
    
    - GIMP: Image → Scale Image
    - Photoshop: Image → Image Size
    - ImageMagick: `convert input.png -resize 28x28! output.png`
  </Step>
  
  <Step title="Use inverted colors">
    Draw your digit in white on a black background. This matches the MNIST training data format.
    
    <Info>
      MNIST digits were originally black on white, but the dataset stores them inverted with pixel values where higher values represent the digit.
    </Info>
  </Step>
  
  <Step title="Center the digit">
    Position your digit in the center of the 28×28 canvas, similar to MNIST samples. Off-center digits may be misclassified.
  </Step>
  
  <Step title="Keep it simple">
    Use clear, simple strokes. The network was trained on handwritten digits, so avoid fancy fonts or decorative styles.
  </Step>
</Steps>

## Making a prediction

<Steps>
  <Step title="Ensure model weights exist">
    Verify that trained weights are available:
    
    ```bash
    ls data/hweights.model data/oweights.model
    ```
    
    If these files don't exist, train the model first:
    
    ```bash
    go run cmd/main.go -mnist train
    ```
  </Step>
  
  <Step title="Run prediction on your image">
    Execute the prediction command:
    
    ```bash
    go run cmd/main.go -file examples/digit_7.png
    ```
    
    Example output:
    ```
    [Image displayed in terminal]
    ⎡0.01234⎤
    ⎢0.00891⎥
    ⎢0.02156⎥
    ⎢0.01445⎥
    ⎢0.00678⎥
    ⎢0.01092⎥
    ⎢0.00234⎥
    ⎢0.98765⎥
    ⎢0.01567⎥
    ⎣0.00982⎦
    prediction: 7
    ```
  </Step>
</Steps>

## How it works

The `predictFromImage` function in `/cmd/main.go:158` handles custom image prediction:

```go
func predictFromImage(net perceptron.Network, path string) int {
    input := dataFromImage(path)
    output := net.Predict(input)
    perceptron.MatrixPrint(output)
    best := 0
    highest := 0.0
    for i := 0; i < net.Outputs; i++ {
        if output.At(i, 0) > highest {
            best = i
            highest = output.At(i, 0)
        }
    }
    return best
}
```

### Image preprocessing

The `dataFromImage` function in `/cmd/main.go:173` converts your PNG into the format the network expects:

```go
func dataFromImage(filePath string) (pixels []float64) {
    // read the file
    imgFile, err := os.Open(filePath)
    defer imgFile.Close()
    if err != nil {
        fmt.Println("Cannot read file:", err)
    }
    img, err := png.Decode(imgFile)
    if err != nil {
        fmt.Println("Cannot decode file:", err)
    }

    // create a grayscale image
    bounds := img.Bounds()
    gray := image.NewGray(bounds)

    for x := 0; x < bounds.Max.X; x++ {
        for y := 0; y < bounds.Max.Y; y++ {
            rgba := img.At(x, y)
            gray.Set(x, y, rgba)
        }
    }
    // make a pixel array
    pixels = make([]float64, len(gray.Pix))
    // populate the pixel array subtract Pix from 255 because
    // that's how the MNIST database was trained (in reverse)
    for i := 0; i < len(gray.Pix); i++ {
        pixels[i] = (float64(255-gray.Pix[i]) / 255.0 * 0.99) + 0.01
    }
    return
}
```

### Preprocessing steps

<Steps>
  <Step title="Load PNG file">
    The image is loaded using Go's standard `image/png` decoder.
  </Step>
  
  <Step title="Convert to grayscale">
    If the image is RGB or RGBA, it's converted to grayscale. This ensures consistent single-channel input.
  </Step>
  
  <Step title="Invert pixel values">
    The crucial step: `255 - gray.Pix[i]`
    
    This inverts the pixel values because MNIST training data has higher values for the digit itself:
    
    - Black pixel (0) → 255 (after inversion)
    - White pixel (255) → 0 (after inversion)
    
    <Warning>
      If your image has a white digit on black background, this inversion ensures the digit has high pixel values, matching MNIST format.
    </Warning>
  </Step>
  
  <Step title="Normalize to 0.01-0.99">
    Each pixel is normalized using the same formula as training:
    
    ```go
    pixels[i] = (float64(255-gray.Pix[i]) / 255.0 * 0.99) + 0.01
    ```
    
    This scales values to the range [0.01, 0.99], avoiding extreme values that could cause numerical instability in the sigmoid function.
  </Step>
  
  <Step title="Create 784-element input vector">
    The 28×28 pixel grid (784 pixels total) becomes a flat array passed to the neural network's input layer.
  </Step>
</Steps>

## Understanding the output

The prediction displays a matrix of 10 confidence values:

```
⎡0.01234⎤  ← Confidence for "0"
⎢0.00891⎥  ← Confidence for "1"
⎢0.02156⎥  ← Confidence for "2"
⎢0.01445⎥  ← Confidence for "3"
⎢0.00678⎥  ← Confidence for "4"
⎢0.01092⎥  ← Confidence for "5"
⎢0.00234⎥  ← Confidence for "6"
⎢0.98765⎥  ← Confidence for "7" (highest)
⎢0.01567⎥  ← Confidence for "8"
⎣0.00982⎦  ← Confidence for "9"
```

The final prediction is the index with the highest confidence value.

## Troubleshooting

### Low confidence predictions

If all confidence values are similar (around 0.1), the network is uncertain:

- **Check image dimensions**: Must be exactly 28×28 pixels
- **Verify color inversion**: Use white digit on black background
- **Check centering**: Digit should be centered like MNIST samples
- **Retrain if needed**: Model may not be properly trained

### Wrong predictions

If the network consistently misclassifies:

- **Compare with MNIST samples**: Ensure your style matches training data
- **Check line thickness**: Very thin or thick lines may confuse the network
- **Verify preprocessing**: Make sure the image loads correctly
- **Test with MNIST test set**: Run `-mnist predict` to verify model accuracy

### Image display issues

The `printImage` function uses iTerm2's inline image protocol. If the image doesn't display:

- This is normal for most terminals
- The prediction still works correctly
- Use iTerm2 on macOS for image preview support

<Info>
  Image display is optional and doesn't affect prediction accuracy. The feature uses the iTerm2 inline image protocol for convenience.
</Info>

## Example workflow

Here's a complete workflow for testing a custom digit:

```bash
# 1. Train the model (if not already trained)
go run cmd/main.go -mnist train

# 2. Verify model accuracy on test set
go run cmd/main.go -mnist predict

# 3. Create a 28×28 PNG with a white digit on black background
# (use your favorite image editor)

# 4. Predict your custom image
go run cmd/main.go -file my_digit.png
```

## Next steps

Now that you can classify custom images, you might want to:

- Experiment with different handwriting styles
- Create a batch prediction script for multiple images
- Build a web interface that accepts image uploads
- Modify the preprocessing pipeline for different image formats